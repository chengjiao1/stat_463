{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lecture-1   \n",
    "\n",
    "#  Chapter1: Sampling and Descriptive Statistics\n",
    "\n",
    "![](image/lec1-1.png)\n",
    "\n",
    "### Definition\n",
    "\n",
    "* Statistics: science of collection, organization, summarization and analysis of data.\n",
    "* Population: entire collection of objects or outcomes about which information is sought.\n",
    "* Sample: subset of a population, containing the objects or outcomes that are actually observed.\n",
    "* Simple random sample (SRS): a sample chosen by a method that each collection of n Population items is equally likely to comprise the sample.\n",
    "* Sample of convenience: a sample that is not drawn by a well-defined random method.\n",
    "\n",
    "### Statistic and Parameter:\n",
    "\n",
    "* A numerical summary of a sample is called a statistic. Such as: sample mean, sample maximum.\n",
    "* A numerical summary of a Population is called a statistic. Such as: population mean, population maximum.\n",
    "\n",
    "Statistics are ooften used to estimate parameters.\n",
    "\n",
    "### Types of Data\n",
    "\n",
    "* Numerical or quantitative: Height, Weight, Age.\n",
    "* Categorical or qualitative: Hair color, Country of origin, Zip code, Social Security Number.\n",
    "\n",
    "### Experiment Types\n",
    "\n",
    "* Controlled experiment: experimenter controls the values of the factors.\n",
    "* Obervational study: experimenter simply observes the factors without any control over them.\n",
    "\n",
    "### Sample Mean\n",
    "\n",
    "\\begin{equation*}\n",
    "\\overline{X} = \\frac{1}{n}\\sum_{i=1}^n{X_i}\n",
    "\\end{equation*}\n",
    "\n",
    "if $\\begin{equation*}\n",
    "Y_i = a+bX_i\n",
    "\\end{equation*}$ where a, b are constants, then\n",
    "$\\begin{equation*}\n",
    "\\overline{Y} = a+b\\overline{X}\n",
    "\\end{equation*}$\n",
    "\n",
    "### Sample Variance\n",
    "\n",
    "\\begin{equation*}\n",
    "S^2 = \\frac{1}{n-1}\\sum_{i = 1}^n({X_i-\\overline{X})^2} = \\frac{1}{n-1}(\\sum_{i = 1}^n({X_i^2-n\\overline{X}^2)}\n",
    "\\end{equation*}\n",
    "\n",
    "Sample Standard Deviation:\n",
    "\n",
    "\\begin{equation*}\n",
    "S = +\\sqrt{S^2}\n",
    "\\end{equation*}\n",
    "\n",
    "if $\\begin{equation*}\n",
    "Y_i = a+bX_i\n",
    "\\end{equation*}$ where a, b are constants, then\n",
    "$\\begin{equation*}\n",
    "S_y^2 = b^2S_x^2\n",
    "\\end{equation*}$ and,hence\n",
    "$\\begin{equation*}\n",
    "S_y = |b|S_x\n",
    "\\end{equation*}$\n",
    "\n",
    "### Median\n",
    "\n",
    "Median is the midpoint a sample data set.\n",
    "\n",
    "if n is odd, its position: $\\frac{n+1}{2}$\n",
    "if n is even, the median is the average of the numbers in the position $\\frac{n}{2}$ and $\\frac{n}{2}+1$.\n",
    "\n",
    "### Quartiles \n",
    "\n",
    "Quartiles divide data into 4 equal parts(quarters). \n",
    "\n",
    "* The first quartile orlower quartile($Q_1$):the median of data below median(25%).\n",
    "* The second quartile($Q_2$):the Median(50%).\n",
    "* The third quartile or upper quartile($Q_3$):the median of data above median(75%).\n",
    "\n",
    "Percentile: at the position of pth, p%of the sample valve below pth, (100-p)% are greater.\n",
    "\n",
    "### Example  \n",
    "\n",
    "Suppose we have the following numerical data: 5, 8, 12, 6, 3, 3, 2, 9.\n",
    "\n",
    "sample mean: $\\overline{X}$ = $\\frac{1}{8}\\sum_{i=1}^8{X_i}$ = $\\frac{1}{8}$ $\\times48$ = 6\n",
    "\n",
    "sample variance: $S^2$ = $\\frac{1}{8-1}(\\sum_{i = 1}^8{X_i^2-8\\overline{X}^2)}$ = $\\frac{1}{7}$ $\\times(372-8*36)$ = 12\n",
    "\n",
    "sample median: order the data set from low to high as: 2, 3, 3, 5, 6, 8, 9, 12.so the median is: $\\frac{5+6}{2}$ = 5.5\n",
    "\n",
    "the first quartile: order the data set from smallest to largest frist, then caculate its position as 25%*8=2, and we get $Q_1$ = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lecture-2     \n",
    "\n",
    "# Chapter 1: Sampling and Descriptive Statistics\n",
    "\n",
    "### Graphical Summaries\n",
    "\n",
    "#### Stem-and-leaf plot\n",
    "![](image/lec2-1.png)\n",
    "* can represent the data,for example:5, 7, 11, 12.\n",
    "* can show the shape of the sample.\n",
    "* can reconstruct the data in its entirety from a stem-and-leaf plot.\n",
    "\n",
    "#### Dotplot \n",
    "![](image/lec2-2.png)\n",
    "* can give a rough impression of the shape of a sample.\n",
    "* used for continuous, quantitative, univariate data.\n",
    "* can be used when sample size not large and the sample contains repeated value.\n",
    "\n",
    "#### Histogram\n",
    "![](image/lec2-3.png)\n",
    "* can represent the shape of the sample.\n",
    "* should have a reasonable observation in each interval.\n",
    "* the bar touch each other, a space indicates that there are no observation in that interval.\n",
    "\n",
    "#####  * Symmetry and Skewness\n",
    "1) Definition\n",
    "* Symmetry: its right half is a mirror image of its left half.\n",
    "* Skewed to the left or negatively skewed: with a long left-hand tail.\n",
    "* Skewed to the right or positively skewed: with a long right-hand tail.\n",
    "* Unimoda: a histogram with only one peak.\n",
    "* Bimodal: a histogram has two peaks.\n",
    "* Multimodal: a histogram with more than two peaks.\n",
    "\n",
    "2) Relation to Mean and Median\n",
    "* for a symmetric histogram, the mean and median are approximately equal.\n",
    "* for a right-skewed histogram, the mean is greater than the median.\n",
    "* for a left-skewed histogram, the mean is less than the median.\n",
    "\n",
    "#### Boxplot:\n",
    "![](image/lec2-4.png)\n",
    "* presents $Q_1$,$Q_2$,$Q_3$ and outliers present in the sample.\n",
    "\n",
    "##### * IQR and Outliers\n",
    "* Interquartile range(IQR) = $Q_3$-$Q_1$,it is the difference between the third quartile and the first quartile.  \n",
    "* Outliers: sample points smaller than $Q_1$ or larger than $Q_3$, they are maybe entry errors or really different from the rest points value.\n",
    "\n",
    "#### Scatterplot\n",
    "![](image/lec2-5.png)\n",
    "* used in bivariate(items consists of a pairof values) data summary.\n",
    "* if the dots ate spread out in random scatter, then the two variables are not well related to each other.\n",
    "* if the dots are spread around a straight line, then one variable can be used to help predict the value of the other variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lecture-3\n",
    "\n",
    "# Chapter 2: Probability\n",
    "\n",
    "### Definition\n",
    "\n",
    "- Experiment: is a process that results on an outcome that cannot be predicted in advance with certainty.\n",
    "- Sample space: the set of all possible outcomes.\n",
    "- Event: is a subset of the sample space.\n",
    "\n",
    "### Combining  Events\n",
    "- Union: the set of outcomes that belong to either envet A or B, or both,denoted by A$\\bigcup$B, which means A or B.\n",
    "- Intersection: the set of outcomes that belong to both envets A and B, or both,denoted by A$\\bigcap$B, which means A and B.\n",
    "- Complement: the complement of an event A is the set of outcomes that not in A, denoted by $A^c$, which means not A.\n",
    "\n",
    "The combining of teo events can be demonstrated by Venn Diagram.\n",
    "\n",
    "### Example\n",
    "\n",
    "Draw balls which labled with number as:5, 8, 10, 25, 31 from a box.Then, \n",
    "\n",
    "draw balls is an event.\n",
    "\n",
    "the possible outcome of the number S = {5, 8, 10, 25, 31}is the sample space.\n",
    "\n",
    "the subset of sample space A = {5, 10, 25}, B = {5,25,31} is called event A:the number is the multiple of 5, and event B:the number is odd.\n",
    "\n",
    "the union of event A and B is: A$\\bigcup$B = {5, 10, 25, 31}.\n",
    "\n",
    "the intersection of event A and B is: A$\\bigcap$B = {10, 25}.\n",
    "\n",
    "the complement of event A is: $A^c$ = {8, 31}.\n",
    "\n",
    "can be demonstrated by Venn Diagram as below:\n",
    "\n",
    "![](image/lec3-1.png)\n",
    "\n",
    "### Mutually Exclusive Events\n",
    "\n",
    "- Events A and B have no outcomes in common, then they are mutually exclusive events or disjoint events.Denoted by: A$\\bigcap$B = $\\phi$.\n",
    "\n",
    "### Probability\n",
    "\n",
    "- The probabilty of an event is a quantitative measure of the possibility of the event is to occur.Denoted by: P(A).\n",
    "\n",
    "###  Formula of Probability\n",
    "\n",
    "- P(S)=1\n",
    "- For any event A: 0 $\\leq$ P(A) $\\leq$ 1, P($A^c$) = 1-P(A)\n",
    "- For mututally exclusive events,P(A $\\bigcup$ B) = P(A)+P(B)\n",
    "- For any empty event $\\phi$: P($\\phi$) = 0\n",
    "- if A = {$O_1, O_2,...,O_n$}: P(A) = $P(O_1)+P(O_2)+...+P(O_n)$\n",
    "\n",
    "#### Additional rules\n",
    "\n",
    "- P(A $\\bigcup$ B) = P(A)+P(B) - P(A$\\bigcup$B)\n",
    "- P(A$\\bigcup$B$\\bigcup$C) = P(A) + P(B) + P(C) - P(A$\\bigcap$B) - P(B$\\bigcap$C) - P(C$\\bigcap$A) + P(A$\\bigcap$B$\\bigcap$C)\n",
    "- P($A_1$ $\\bigcup$...$\\bigcup$ $A_n$) = $\\sum_{i=1}^n$P($A_i)$ - $\\sum_{i<j} $P($A_i$ $\\bigcap$ $A_j$) + $\\sum_{i<j<k}$P($A_i$ $\\bigcap$ $A_j$ $\\bigcap$ $A_k$) +...+ $(-1)^{n-1}$P($A_1$ $\\bigcap$ $A_2$ $\\bigcap$...$\\bigcap$ $A_n$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lecture-4\n",
    "\n",
    "# Chapter 2: Probability\n",
    "\n",
    "### Conditional Probability\n",
    "\n",
    "* The conditional Probability of A given B is: \n",
    "\n",
    "\\begin{align}\n",
    "P(A|B) = \\frac{P(A \\bigcap {B})}{P(B)}\n",
    "\\end{align}\n",
    "\n",
    "* $P(A \\bigcap {B})$ = P(A)P(B|A) = P(B)P(A|B)\n",
    "\n",
    "### Independence\n",
    "\n",
    "* If either P(A) = 0 or P(B) = 0, then A and B are independent.\n",
    "* If P(A|B) = P(A) or P(B|A) = P(B), then A and B are independent,and $P(A \\bigcap {B})$ = P(A)P(B)\n",
    "* If $A_i, ...,A_n$ are independent events,for each collection of events $A_{j1}, ..., A_{jm}$\n",
    "\n",
    "\\begin{align}\n",
    "P(A_{j1} \\bigcap {A_{j2}} \\bigcap...\\bigcap {A_{jm}}) = P(A_{j1})P(A_{j2})...P(A_{jm})\n",
    "\\end{align}\n",
    "\n",
    "in particular,\n",
    "\n",
    "\\begin{align}\n",
    "P({A_1} \\bigcap {A_2} \\bigcap... \\bigcap {A_n}) = P(A_1)P(A_2)...P(A_n)\n",
    "\\end{align}\n",
    "\n",
    "### Law of Total Probability\n",
    "* If$ A_1, ..., A_n$ are mutually exclusive and exhaustive events and B is any event, then, P(B) = $P({A_1} \\bigcap {B}) +...+ P({A_n} \\bigcap ${B})$ = P(B|A_1)P(A_1)+...+P(B|A_n)P(A_n)$\n",
    "\n",
    "### Bayes' Rule\n",
    "* Let $A_1,..., A_n$ be mutually exclusive and exhaustive events, with $P(A_j) \\neq 0$ for each i.Let B be any event with $P(B) \\neq 0$. Then,\n",
    "![](image/lec4-1.png)\n",
    "\n",
    "\\begin{align}\n",
    "P(A_k|B) = \\frac{P(B|A_k)P(A_k)}{\\sum_{i=1}^nP(B|A_i)P(A_i)}\n",
    "\\end{align}\n",
    "\n",
    "### Example\n",
    "Laura and Philip each fire one shot at a target. Laura has probability 0.5 of hitting the target, and Philip has probability 0.3. Their shots are independent.\n",
    "\n",
    "(1) Find the probability that the target is hit.\n",
    "\n",
    "(2) Find the probability that the target is hit by exactly one shot.\n",
    "\n",
    "(3) Given that the target was hit by exactly one shot, find the probability that Laura hit the target.\n",
    "\n",
    "Solution:\n",
    "(1) P(L ∪ P) = P(L) + P(P) − P(L ∩ P) = P(L) + P(P) − P(L)P(P) = 0.5 + 0.3 − 0.5 × 0.3 = 0.65\n",
    "(2) P((L ∩ {P^c} ) ∪ ({L^c} ∩ P)) = P(L ∩ {P^c} ) + P({L^c} ∩ P) = P(L)P({P^c} ) + P({L^c} )P(P)$ = 0.5 × (1 − 0.3) + (1 − 0.5) × 0.3 = 0.35 + 0.15 = 0.5\n",
    "(3) P(L|(L ∩ {P^c} ) ∪ ({L^c} ∩ P)) = \\frac{P(L∩{P^c})}{P((L∩{P^c})∪({L^c}∩P))} = \\frac{0.5×0.7}{0.5}$ = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Lecture-5\n",
    "\n",
    "# Chapter 2: Probability\n",
    "\n",
    "### Random Variables\n",
    "\n",
    "- Random Variable: a function that assigns a numerical value to each outcome of a sample space. Denoted by X, Y, Z etc.\n",
    "\n",
    "### Types of random variables\n",
    "\n",
    "1) Descrete\n",
    "- values are separated by gaps.\n",
    "- number of values countable.\n",
    " \n",
    "2) Continuous\n",
    "- no gaps between individual values.  \n",
    "- numbers of values is infinite(uncountable).\n",
    "\n",
    "### Probability Distribution Function\n",
    "\n",
    "1) Descrete\n",
    "\n",
    "- Probability Mass Function(pmf): p(x) = P(X=x)\n",
    "- $p(x) \\geq 0$\n",
    "- $\\sum_x$p(x) = 1\n",
    "\n",
    "2) Continuous \n",
    "\n",
    "- Probability density function(pdf): f(x)\n",
    "- f(x) $\\geq$0\n",
    "- $\\int_{-{\\infty}}^{\\infty}f(x)\\mathrm{d}x$ = 1\n",
    "- Probability for continuous random variables are found as areas under the pdf curve. P$(X\\in{A}) = \\int_Af(x)\\mathrm{d}x$\n",
    "- Computing Probabilities:\n",
    "\n",
    "  1) P(X = a) = 0\n",
    " \n",
    "  2) P(X = a) $\\neq$ f(a)\n",
    "\n",
    "  3) P$(X{\\leq}a) = P(X<a) = \\int_{-\\infty}^a{f(x)}{d}x$\n",
    "  \n",
    "  4) P$(X{\\geq}a) = P(X>a) = \\int_a^{\\infty}{f(x)}{d}x$\n",
    "  \n",
    "  5) P(a<X<b) = P$(a<X{\\leq}b) = ... = P(a{\\leq}X{\\leq}b) = \\int_a^b{f(x)}{d}x$\n",
    "  \n",
    "### Cumulative Distribution Function(cdf)\n",
    "\n",
    "1) Descrete\n",
    "\n",
    "- F(x) = P(X$\\leq$x) = $\\sum_{t\\leq{x}}P(t)$\n",
    "- p(x) = F(x)-F(x-)\n",
    "\n",
    "2) Continuous \n",
    "\n",
    "- F(x) =  $\\int_{-\\infty}^x{f(t)}{d}t$\n",
    "- f(x) = $\\frac{d}{{d}x}F(x)$\n",
    "\n",
    "### Expected Valve E(X)\n",
    "\n",
    "1) Descrete\n",
    "\n",
    "- Mean of a discrete random variable X or expected value or average of X with pmf p(x) is $\\mu = \\sum_xxp(x)$\n",
    "\n",
    "2) Continuous\n",
    "\n",
    "$\\mu = \\int_{-\\infty}^{\\infty}x{f(x)}{d}x$\n",
    "\n",
    "### Variance\n",
    "\n",
    "1) Descrete\n",
    "\n",
    "$\\sigma^2 = \\sum_x(x-\\mu)^2p(x) = \\sum_xx^2p(x)-\\mu^2$\n",
    "\n",
    "$\\sigma = +\\sqrt\\sigma^2$ \n",
    "\n",
    "2) Continuous\n",
    "\n",
    "$\\sigma^2 = \\int_{-\\infty}^{\\infty}(x-{\\mu})^2{f(x)}{d}x = \\int_{-\\infty}^{\\infty}x^2{f(x)}{d}x-{\\mu}^2$\n",
    "\n",
    "### Median and Percentiles (Continuous Random Variable)\n",
    "\n",
    "- Median: P$(X{\\geq}{x_m}) = \\int_{-\\infty}^{x_m}{f(x)}{d}x$ = 0.5\n",
    "- Percentile: P$(X{\\geq}{x_p}) = \\int_{-\\infty}^{x_p}{f(x)}{d}x = \\frac{p}{100}$\n",
    "\n",
    "### Chebyshev's Inequality\n",
    "\n",
    "For any random variable X with Mean $\\mu$ and standard deviation $\\sigma$, \n",
    "P$({|X-{\\mu}|}$ ${\\geq}$ ${{k}{\\sigma}})$ ${\\leq}$ $\\frac{1}{k^2}$    for any k>0.\n",
    "\n",
    "- at least (1-$\\frac{1}{k^2}$)probability of X being within ${\\mu}{\\pm}k{\\sigma}$.\n",
    "\n",
    "1) k=1, at least 0 probability of being within ${\\mu}{\\pm}{\\sigma}$.\n",
    "\n",
    "2) k=2,  at least 3/4 probability of being within ${\\mu}{\\pm}2{\\sigma}$.\n",
    "\n",
    "### Example\n",
    "\n",
    "Let X represent the diameter, in micrometers, of a randomly chosen particle. Assume that in a certain area, the probability density function of X is inversely proportional to the volume of the particle; that is,\n",
    "\n",
    "\\begin{equation}\n",
    "  f(x)=\\begin{cases}\n",
    "    \\frac{c}{x^3}, & {x\\geq1}\\\\\n",
    "    0, & \\text{x<1}\n",
    "  \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "where c is a constant.\n",
    "\n",
    "(1) Find c such that f (x) is a probability density function.\n",
    "\n",
    "(2) Find the cdf of the particle diameter.\n",
    "\n",
    "(3) What proportion of particles are PM 10 (i.e., 10μm or less in\n",
    "diameter)?\n",
    "\n",
    "(4) What proportion of PM 10 particles are PM 2.5 ?\n",
    "\n",
    "(5) Find the median particle diameter.\n",
    "\n",
    "(6) Find the 95th percentile of particle diameter\n",
    "\n",
    "Solution:\n",
    "\n",
    "(1) $\\int_{-\\infty}^{\\infty}{f(x)}{dx}$ = 1, then $\\int_{1}^{\\infty}{\\frac{c}{x^3}}{dx}$ = 1, so, $ c{\\frac{x^{-3+1}}{-3+1}}|_{1}^{\\infty}$ = 1   so ${\\frac{c}{2}}$ = 1,so c = 2.\n",
    "\n",
    "(2) cdf is:\n",
    "\n",
    "\\begin{equation}\n",
    " F(x) =  \\int_{-\\infty}^x{f(x)}{d}x = \\begin{cases}\n",
    "   0, & {x<1}\\\\\n",
    "    1-x^{-2}, & {x{\\geq}1}\n",
    "  \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "(3) $P(X{\\leq}10) = F(10) = 1-(10)^{-2}$ = 0.99\n",
    "\n",
    "(4) $P(X{\\leq}2.5|X{\\leq}10) = \\frac{P(X{\\leq}2.5)}{P(X{\\leq}10)} = \\frac{1-(2.5)^{-2}}{1-(10)^{-2}}$ = 0.85\n",
    "\n",
    "(5) Median \n",
    "$\\int_{-\\infty}^{x_m}{f(x)}{dx}$ = 0.5, then $\\int_{1}^{x_m}{\\frac{2}{x^3}}{dx}$ = 0.5, that is, 1-${X_m}^{-2}$ = 0.5, so $ {x_m} = \\sqrt{2}$ = 1.41\n",
    "\n",
    "(6) 95th percentile\n",
    "$\\int_{1}^{x_{.95}}{\\frac{2}{x^3}}{dx}$ = 0.95, that is, 1-${x_{.95}}^{-2}$ = 0.95, so $ {x_{.95}} = \\sqrt{20}$ = 4.47\n",
    "\n",
    "$2.$  Elongation (in percent) of steel plates treated with aluminum are random with pdf\n",
    "\\begin{equation}\n",
    "  f(x)=\\begin{cases}\n",
    "    \\frac{x}{250}, & {20<x<30}\\\\\n",
    "    0, & \\text{otherwise}\n",
    "  \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "(1) Find the mean elongation.\n",
    "\n",
    "(2) Find the standard deviation of elongation.\n",
    "\n",
    "Solution:\n",
    "\n",
    "(1) ${\\mu} = {\\int}_{-\\infty}^{\\infty}x{f(x)}{dx} ={\\int}_{20}^{30}x{\\frac{x}{250}}dx = {\\frac{x^3}{750}}|_{20}^{30}$= 25.33\n",
    "\n",
    "(2) Var(X) = ${\\int}_{20}^{30}{x^2}{\\frac{x}{250}}dx - (25.33)^2$ = 8.3911\n",
    "\n",
    "SD(X) = $\\sqrt{8.3911}$ = 2.8967\n",
    "\n",
    "$3.$ A random variable X has mean μ = 3 and standard deviation σ = 0.5.\n",
    "\n",
    "(1) What can you say about P(1 < X < 5)?\n",
    "\n",
    "(2) What can you say about P(X ≤ 2)?\n",
    "\n",
    "solution:\n",
    "\n",
    "(1) P(1 < X < 5) = $p({\\mu}-4{\\sigma} < X<{\\mu}+4{\\sigma} = p(|X-{\\mu}|< 4{\\sigma}){\\geq} 1-\\frac{1}{4^2} $ = 0.9375\n",
    "\n",
    "(2) $p(X{\\leq}2) = p(X{\\leq}{\\mu}-2{\\sigma})$ ${\\leq}$ $\\frac{1}{2}$[$P(X{\\leq}{\\mu}-2{\\sigma}$)+P$(X{\\geq}{\\mu}+2{\\sigma})$] = $\\frac{1}{2}$p$(|X-{\\mu}|{\\geq}2{\\sigma}$)${\\leq}$ $\\frac{1}{2^2}$ ${\\frac{1}{2}}$ = 0.125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lecture-6\n",
    "\n",
    "# Chapter 4: Commonly Used Distributions\n",
    "\n",
    "### Bernoulli Distribution  X~Bernoulli(p)\n",
    "\n",
    "- Bernoulli trial:two possible outcomes: \"success\"(S) or \"failure\"(F)\n",
    "- Bernoulli random variable\n",
    "\n",
    "\\begin{equation}\n",
    "  X=\\begin{cases}\n",
    "    1, & \\text{if \"success\"}\\\\\n",
    "    0, & \\text{if \"failure\"}\n",
    "  \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "- Denoted by: X~Bernoulli(p), where p = P(S)\n",
    "\n",
    "#### properties:\n",
    "\n",
    "- pmf\n",
    "\n",
    "\\begin{equation}\n",
    "  p(x)=\\begin{cases}\n",
    "    1-p, & \\text{if x=0}\\\\\n",
    "    p, & \\text{if x=1}\\\\\n",
    "    0, & \\text{oterwise}\n",
    "  \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "- Mean: $\\mu$ = p\n",
    "\n",
    "- Variance: $\\sigma^2$ = p(1-p)\n",
    "\n",
    "### Binomial Distribution X~ Bin(n,p)\n",
    "\n",
    "- N independent Bernoulli trials, each trial has same success probability P\n",
    "- Let X = number of successes in the n trials, then X is said to have a binomial distribution with parameters in n and p. Denoted by X~ Bin(n,p).\n",
    "\n",
    "**** Note\n",
    "\n",
    "1) In a finite population containing 2 types of items (defective and non-defective), the number of defectives in a sample of size n is not strictly binomial.\n",
    "\n",
    "2) If the sample is a small fraction (≤ 5%) of the population, binomial distribution can be a good approximation.\n",
    "\n",
    "#### Properties:\n",
    "\n",
    "- pmf\n",
    "\n",
    "\\begin{equation}\n",
    "  p(x)=\\begin{cases}\n",
    "   \\frac{n!}{x!(n-x)!} p^x(1-p)^{n-x}, & \\text{if x=0, 1 ..., n}\\\\\n",
    "    0, & \\text{oterwise}.\n",
    "  \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "- Mean: $\\mu$ = np\n",
    "\n",
    "- Variance: $\\sigma^2$ = np(1-p)\n",
    "\n",
    "#### Relation between Bernoulli and binomial\n",
    "\n",
    "- Sum of independent Bernoullis is binomial.\n",
    "- suppose $Y_i$ ~ Bernoulli(p), i = 1, ..., n, $Y_i$'s are independent, X = $Y_i+...+Y_n$, then X~Bin(n,p).\n",
    "\n",
    "#### Estimating \n",
    "\n",
    "- if a set of n independent Bernoulli trials results in X successes\n",
    "\n",
    "1) estimate of p is: $\\hat{p}$ = X/n\n",
    "\n",
    "2) uncertainty in the estimate is: \n",
    "\n",
    "\\begin{equation}\n",
    "{{\\sigma}_{\\hat{p}}} = \\sqrt{\\frac{p(1-p)}{n}}\n",
    "\\end{equation}\n",
    "\n",
    "3) estimated is: \n",
    "\n",
    "\\begin{equation}\n",
    "{\\hat{\\sigma}_{\\hat{p}}} = \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\n",
    "\\end{equation}\n",
    "\n",
    "#### Linear Functions of Random Variables\n",
    "\n",
    "* If X is a random variable and a and b are constants, we have E(aX+b) = aE(X)+b, and Var(aX+b) = $a^2$Var(X).\n",
    "\n",
    "### Poisson Distribution X ~ Poisson( $\\lambda$)\n",
    "\n",
    "- pmf(Probability Mass Function) is given by\n",
    "\n",
    "\\begin{equation}\n",
    "  p(x)=\\begin{cases}\n",
    "   \\frac{{e^{-\\lambda}}{\\lambda}^{x}}{x!}, & \\text{x=0, 1 ..., n}\\\\\n",
    "    0, & \\text{oterwise}.\n",
    "  \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    " Parameter: $\\lambda$ > 0. Notation: X ~ Poisson( $\\lambda$)\n",
    " \n",
    "- Mean: $\\mu$ = $\\lambda$\n",
    "\n",
    "- Variance: $\\sigma^2$ = $\\lambda$\n",
    "\n",
    "#### Limiting case of binomial distribution:\n",
    "\n",
    "1) large number if trials(n $\\to$ $\\infty$)\n",
    "\n",
    "2) small probability of success in each trial(p $\\to$ 0)\n",
    "\n",
    "3) np = $\\lambda$\n",
    "\n",
    "#### Estimating \n",
    "\n",
    "1) If X ∼ Poisson(${\\lambda}t$), estimate λ with $\\hat{\\lambda} = \\frac{X}{t}$.\n",
    "\n",
    "2) E($\\hat{\\lambda}) = {\\lambda}$ (unbiased)\n",
    "\n",
    "3) uncertainty in the estimate is: \n",
    "\n",
    "\\begin{equation}\n",
    "{{\\sigma}_{\\hat{\\lambda}}} = \\sqrt{\\frac{\\lambda}{t}}\n",
    "\\end{equation}\n",
    "\n",
    "4) estimated is: \n",
    "\n",
    "\\begin{equation}\n",
    "{\\hat{\\sigma}_{\\hat{\\lambda}}} = \\sqrt{\\frac{X}{t^2}}\n",
    "\\end{equation}\n",
    "\n",
    "#### Example\n",
    "\n",
    "1. A general contracting firm experiences cost overruns on 20% of its contracts. In a company audit, 20 contracts are sampled at random. Find\n",
    "\n",
    "(1) P(exactly 4 experience cost overruns)\n",
    "\n",
    "(2) P(fewer than three experience cost overruns)\n",
    "\n",
    "(3) P(none of them experience cost overruns)\n",
    "\n",
    "(4) Mean number that experience cost overruns\n",
    "\n",
    "(5) Standard deviation of the number that experience cost overruns.\n",
    "\n",
    "Solution:\n",
    "\n",
    "X ∼ Bin(20, 0.2)\n",
    "\n",
    "(1) P(X = 4) = $(_4^{20})(0.2)^4(0.8)^{16}$ = 0.2182\n",
    "\n",
    "(2) p(X < 3) = $(_0^{20})(0.2)^0(0.8)^{20}+(_1^{20})(0.2)^1(0.8)^{19}+(_2^{20})(0.2)^2(0.8)^{18}$ = 0.2060\n",
    "\n",
    "(3) P(X = 0) = $(_0^{20})(0.2)^0(0.8)^{20}$ = 0.0115\n",
    "\n",
    "(4) $\\mu_x = 20{\\times}0.2$ = 4\n",
    "\n",
    "(5) $\\sigma_x$ = $\\sqrt{20{\\times}0.2{\\times}0.8}$ = 1.7888\n",
    "\n",
    "$2. $ A certain type of circuit board contains 300 diodes. Each diode has probability p = 0.002 of failing.\n",
    "\n",
    "(1) Find P(exactly 2 diodes fail)\n",
    "\n",
    "(2) Find mean number of diodes that fail\n",
    "\n",
    "(3) Find standard deviation of the number of diodes that fail\n",
    "\n",
    "(4) A board works if none of its diodes fail. Find P(board works)\n",
    "\n",
    "(5) Five boards are shipped to a customer. Find P(four or more of them work)\n",
    "\n",
    "Solution:\n",
    "\n",
    "X ∼ Bin(n = 300, p = 0.002). Since n is large, p is small and np = 0.6, we will approximate this distribution using Poisson(λ = 0.6).\n",
    "\n",
    "(1) P(X = 2) = $e^{-0.6}$ $(0.6)^2 /(2!)$ = 0.0988 \n",
    "\n",
    "(2) E (X ) = 0.6\n",
    "\n",
    "(3) ${\\sigma} = \\sqrt{\\lambda} = \\sqrt{0.6}$ = 0.7738\n",
    "\n",
    "(4) P(board works) = $P(X = 0)$ = $e^{-0.6}$ = 0.5485\n",
    "\n",
    "(5) Let Y = number of boards (out of the 5) that work. Then Y ∼ Bin(5, 0.5485). so\n",
    "P(Y ≥ 4) = $(_4^5)$ $(0.5485)^4$ (1 − 0.5485) + (_5^5) $(0.5485)^5$ = 0.2544.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Lecture-7\n",
    "\n",
    "# Chapter 4: Commonly Used Distributions\n",
    "\n",
    "### Normal Distribution X ~ N(${\\mu},{\\sigma}^2$)\n",
    "\n",
    "![](image/lec6-1.png)\n",
    "\n",
    "- Denoted by: X ~ N(${\\mu},{\\sigma}^2$)\n",
    "\n",
    "- with mean $\\mu$, variance $\\sigma^2$. Also known as Gaussian distribution.\n",
    "\n",
    "- pdf( probability density function):\n",
    "\n",
    "\\begin{equation}\n",
    "{f(x) = \\frac{1}{{\\sqrt{2{\\pi}}}{\\sigma}}{e}^{-(x-{\\mu})^2/(2{\\sigma}^2)}},   {-\\infty} < x < {\\infty}\n",
    "\\end{equation}\n",
    "\n",
    "- E(X) = $\\mu$\n",
    "\n",
    "- Var(X) = ${\\sigma}^2$\n",
    "\n",
    "- Rule\n",
    "\n",
    "1) About 68% of the population is in the interval ${\\mu} {\\pm} {\\sigma}$\n",
    "\n",
    "2) About 95% of the population is in the interval ${\\mu} {\\pm} 2{\\sigma}$\n",
    "\n",
    "3) About 99.7% of the population is in the interval ${\\mu} {\\pm} 3{\\sigma}$\n",
    "\n",
    "#### Standard Normal Distribution\n",
    "\n",
    "- N( 0, 1),special case of normal distribution with $\\mu$ = 0 and $\\sigma$ = 1. \n",
    "\n",
    "- Usually denoted by Z\n",
    "\n",
    "#### Relation Between any Normal and Standard Normal\n",
    "\n",
    "- if X ~ N$({\\mu},{\\sigma}^2)$, then Z = $\\frac{X-{\\mu}}{\\sigma}$ ~ N(0,1)\n",
    "\n",
    "- if Z ~ N(0,1), then X = ${\\mu}+{\\sigma}Z$ ~ N$({\\mu},{\\sigma}^2)$.\n",
    "\n",
    "- Z tells us how many standard deviations are they away from the mean.\n",
    "\n",
    "#### Linear Combinations of Normal Random Variables\n",
    "\n",
    "- if X ~ N$({\\mu},{\\sigma}^2)$,then for any constants a,b(a $\\neq$ 0): Y = aX + b ~ N $(a{\\mu}+b,a^2{\\sigma}^2)$\n",
    "\n",
    "- if $X_i ~ N({\\mu}_i,{\\sigma}_i^2)$ for i = 1, ...,n and $X_i$'s are independent, than for any constants $c_1, ..., c_n$(not all zero)\n",
    " \n",
    "* Y = $c_1X_1 + ... + c_nX_n ~ N(c_1{\\mu}_1+ ... + )c_n{\\mu}_n,   {c_1}^2{\\sigma_1}^2+ ... +{c_n}^2{\\sigma_n}^2)$\n",
    "\n",
    "* $X_1 + X_2 ~ ({\\mu}_1 + {\\mu}_2, {\\sigma_1}^2 + {\\sigma_2}^2)$\n",
    "\n",
    "* $X_1 - X_2 ~ ({\\mu}_1 - {\\mu}_2, {\\sigma_1}^2 + {\\sigma_2}^2)$\n",
    "\n",
    "### Exponential Distribution X ∼ Exp($\\lambda$)\n",
    "\n",
    "- Used to model waiting times\n",
    "- Determined entirely based on a parameter $\\lambda$ > 0\n",
    "- Denoted by X ∼ Exp($\\lambda$)\n",
    "- pdf( probability density function):\n",
    "\n",
    "\\begin{equation}\n",
    "  f(x)=\\begin{cases}\n",
    "   \\lambda{e}^{-{\\lambda}{x}}, & \\text{x > 0}\\\\\n",
    "    0, & \\text{oterwise}.\n",
    "  \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "- $\\mu = \\frac{1}{\\lambda}$\n",
    "- ${\\sigma}^2 = \\frac{1}{\\lambda}^2$\n",
    "- If events follow a Poisson process with rate $\\lambda$, and the time between any two events is given by T , then T ∼ Exp($\\lambda$).\n",
    "- If T ∼ Exp($\\lambda$), then for any t, s > 0 P(T > t + s|T > s) = P(T > t)\n",
    "\n",
    "#### Example\n",
    "\n",
    "1. A light fixture holds two lightbulbs. Bulb A has normally distributed lifetime with mean of 800 hours and standard deviation of 100 hours. Bulb B has normally distributed lifetime with mean 900 hours and standard deviation 150 hours. Assume that the two bulbs are independent. \n",
    "\n",
    "1) What is the probability that bulb B lasts longer than bulb A? \n",
    "\n",
    "2) What is the probability that bulb B lasts more than 200 hours longer than bulb A? \n",
    "\n",
    "3) Another fixture holds only one bulb. A bulb of type A is installed, and when it burns out, a bulb of type B is installed. What is the probability that the total lifetime of the two bulbs is more than 2000 hours?\n",
    "\n",
    "Solution:\n",
    " \n",
    "Let $X_A$ = lifetime of bulb A and $X_B$ = lifetime of bulb B. then, $X_A$ ∼ $N(800, 100^2)$ and X_B ∼ $N(900, 150^2 )$ with independence of $X_A$ and $X_B$.\n",
    "\n",
    "1) $P(X_B > X_A)$ = $P(X_B - X_A > 0)$ = $P(Z >{\\frac{0-100}{\\sqrt{100^2+150^2}}})$ = P(Z > -0.55) = 0.7088.\n",
    "\n",
    "2) $P(X_B > X_A + 200) = P(X_B - X_A > 200)$ = $P(Z >{\\frac{200-100} {\\sqrt{100^2 + 150^2}}})$ = P(Z > 0.55) = 0.2912.\n",
    "\n",
    "3) $P(X_B + X_A > 2000)$ = $P(Z >{\\frac{2000-1700}{\\sqrt{100^2+150^2}}})$ =  P(Z > 1.66) = 0.0484.\n",
    "\n",
    "${2. }$ The distance between flaws on a long cable is exponentially distributed with mean 12 m.\n",
    "\n",
    "1) Find the probability that the distance between two flaws is between 8m and 20 m.\n",
    "\n",
    "2) Find the median distance.\n",
    "\n",
    "3) Find the standard deviation of distances.\n",
    "\n",
    "4) Find the 65th percentile of distances.\n",
    "    \n",
    "Solution:\n",
    "\n",
    "Let X = distance between flaws on the cable. Known that X ∼ Exp$(\\lambda)$, where$\\frac{1}{\\lambda}$ = 12.\n",
    "\n",
    "1) $P(8 < X < 20) = {\\int_8^{20}}{\\frac{1}{12}}e^{-x/12}dx = e^{-8/12}-e^{-20/12}$ = 0.3245.\n",
    "\n",
    "2) Want $P(X < x_m)$ = 0.5, then, 1 - $e^{-x_m /12}$ = 0.5. so $x_m = -12{\\ln{0.5}}$ = 8.3178.\n",
    "\n",
    "3) $\\sigma =\\frac{1}{\\lambda}$ = 12m\n",
    "\n",
    "4) Want $P(X < x_{0.65})$ = 0.65, that is 1 - $e^{-x_{0.65}/12}$ = 0.65, then, $x_{0.65} = -12{\\ln{0.35}}$ = 12.5979.\n",
    "\n",
    "${3. }$ A radioactive mass emits particles according to a Poisson process at a mean rate of 2 per second. Let T be the waiting time, in seconds,\n",
    "between emissions.\n",
    "\n",
    "1) What is the mean waiting time?\n",
    "2) What is the median waiting time?\n",
    "3) Find P(0.3 < T < 1.5).\n",
    "4) If 3 seconds have elapsed with no emission, what is the probability that there will be an emission within the next second?\n",
    "    \n",
    "Solution: \n",
    "\n",
    "T ∼ Exp(${\\lambda}$ = 2).\n",
    "\n",
    "1) E (T) = $\\frac{1}{\\lambda}$ = 0.5 s\n",
    "\n",
    "2) Want $P(T < t_{0.5})$ = 0.5, then, 1 - $e^{-2t_{0.5}}$ = 0.5. so $t_{0.5} = -0.5{\\ln{0.5}}$ = 0.3466s\n",
    "\n",
    "3) P(0.3 < T < 1.5) = $e^{-0.6}$ - $e^{-3}$ = 0.4990\n",
    "\n",
    "4) P(T < 4|T > 3) = P(3 < T < 4)/P(T > 3) = $\\frac{$e^{-6}$ - e^${-8}}{e^{-6}}$ = 1 - $e^{-2}$ = 0.8647"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
